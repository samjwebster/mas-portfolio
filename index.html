<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Samuel Webster - Portfolio</title>
    <link rel="stylesheet" href="style.css">
</head>
<body style="display: flex; flex-direction: row; align-items: center; justify-content: center; background-color: gray; margin: 0px;">
    <div style="width: 75%; height: 100%; background-color: whitesmoke; margin: 0px; padding: 12px 12px 36px 12px;">
        <h1>Portfolio</h1>
        <h2>Application for The Program in Media Arts & Sciences at the MIT Media Lab</h2>
        <h3>Samuel Webster</h3>
        <hr>
        <p>This portfolio contains work in areas relevant to my application to the following research groups:</p>
        <ul>
            <li>Future Sketches</li>
            <li>Opera of the Future</li>
            <li>Multisensory Intelligence</li>
        </ul>

        <h3>Table of Contents</h3>
        <ul>
            <li><a href="#genart">Generative Art</a></li>
            <li><a href="#research">Research</a></li>
            <li><a href="#projects">Notable Projects</a></li>
        </ul>

        <hr>

        <h1 id="genart">Generative Art</h1>
        <p>All presented works were created using the <a href="https://p5js.org/">p5.js library</a>.</p>

        <h3><em>Airflow</em></h3>
        <p>The generations of <em>Airflow</em> aim to capture an exciting, dynamic, and fluid atmosphere. By utilizing a series of noise maps and thresholds, this work interweaves various flowing patterns with a textured stroke. Multiple blending modes are utilized to add unpredictability to the interaction of drawn colors.</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/airflow/airflow-1.gif" alt="Airflow 1" />
            <img src="data/genart/airflow/airflow-5.png" alt="Airflow 5" />
            <img src="data/genart/airflow/airflow-2.gif" alt="Airflow 2" />
            <img src="data/genart/airflow/airflow-3.png" alt="Airflow 3" />
            <img src="data/genart/airflow/airflow-4.png" alt="Airflow 4" />
            <img src="data/genart/airflow/airflow-6.png" alt="Airflow 6" />
            <img src="data/genart/airflow/airflow-7.png" alt="Airflow 7" />
            <img src="data/genart/airflow/airflow-8.png" alt="Airflow 8" />
            <img src="data/genart/airflow/airflow-9.png" alt="Airflow 9" />
        </div>

        <h3><em>Strata</em></h3>
        <p><em>Strata</em> is the first generative artwork I've published for public minting, using the <a href="https://www.fxhash.xyz/generative/30230">fxhash</a> market. This work is inspired by the flowing layers of geological strata. In order to create visually distinct layers, texture and color gradients are employed. Further, each layer is drawn with a faux shadow beneath it, giving a sense of depth.</p>

        <div class="image-row">
            <img src="data/genart/strata/strata-1.png" alt="Strata 1" />
            <img src="data/genart/strata/strata-2.png" alt="Strata 2" />
            <img src="data/genart/strata/strata-3.png" alt="Strata 3" />
            <img src="data/genart/strata/strata-4.png" alt="Strata 4" />
            <img src="data/genart/strata/strata-5.png" alt="Strata 5" />
            <img src="data/genart/strata/strata-6.png" alt="Strata 6" />
            <img src="data/genart/strata/strata-7.png" alt="Strata 7" />
            <img src="data/genart/strata/strata-8.png" alt="Strata 8" />
            <img src="data/genart/strata/strata-9.png" alt="Strata 9" />
        </div>

        <h2><em>Threads</em></h2>
        <p><em>Threads</em> is a generative artwork that simulates the weaving of threads into a grid-like lattice pattern. The threads are composed of numerous small circles, rendered in order of their depth. The threads are colored on a by-thread basis as well as by considering overall composition. The first draft of this work was created for Genuary 2024, Day 28: "Skeuomorphism".</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/threads/threads-3.gif" alt="Threads 3" />
            <img src="data/genart/threads/threads-10.png" alt="Threads 10" />
            <img src="data/genart/threads/threads-8.png" alt="Threads 8" />
            <img src="data/genart/threads/threads-5.png" alt="Threads 5" />
            <img src="data/genart/threads/threads-2.gif" alt="Threads 2" />
            <img src="data/genart/threads/threads-4.gif" alt="Threads 4" />
            <img src="data/genart/threads/threads-6.png" alt="Threads 6" />
            <img src="data/genart/threads/threads-7.png" alt="Threads 7" />
            <img src="data/genart/threads/threads-1.gif" alt="Threads 1" />
            <img src="data/genart/threads/threads-9.png" alt="Threads 9" />
        </div>

        <h2><em>Space Scenes</em></h2>
        <p>The generations of <em>Space Scenes</em> are imagined from the perspective of a space telescope slowly drifting into, or away from, an unexplored solar system. Despite being rendered on a 2D canvas, the scene simulates depth by drawing in layers: first distant stars, then galaxy clouds, and finally celestial bodies. The planets are 'lit' by the star, considering their position and depth relative to it. The work utilizes dithering to achieve a retro style.</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/space-scenes/space-scene-8.png" alt="Space Scene 8" />
            <img src="data/genart/space-scenes/space-scene-7.png" alt="Space Scene 7" />
            <img src="data/genart/space-scenes/space-scene-5.png" alt="Space Scene 5" />
            <img src="data/genart/space-scenes/space-scene-6.png" alt="Space Scene 6" />
            <img src="data/genart/space-scenes/space-scene-4.png" alt="Space Scene 4" />
            <img src="data/genart/space-scenes/space-scene-1.png" alt="Space Scene 1" />
            <img src="data/genart/space-scenes/space-scene-2.png" alt="Space Scene 2" />
            <img src="data/genart/space-scenes/space-scene-3.png" alt="Space Scene 3" />
        </div>

        <h2><em>Fracti</em></h2>
        In <em>Fracti</em>, a grid-like structure appears shattered, with subsections drifting, folding, and breaking apart in a jagged manner. The work is inspired by the paintings of Piet Mondrian, but if they were in disarray. The piece weilds randomness to dissect a grid into pieces in a dynamic fashion.

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/fracti/fracti-2.png" alt="Fracti 2" />
            <img src="data/genart/fracti/fracti-1.png" alt="Fracti 1" />
            <img src="data/genart/fracti/fracti-7.png" alt="Fracti 7" />
            <img src="data/genart/fracti/fracti-4.png" alt="Fracti 4" />
            <img src="data/genart/fracti/fracti-5.png" alt="Fracti 5" />
            <img src="data/genart/fracti/fracti-6.png" alt="Fracti 6" />
            <img src="data/genart/fracti/fracti-8.png" alt="Fracti 8" />
            <img src="data/genart/fracti/fracti-3.png" alt="Fracti 3" />
        </div>

        <h2><em>Prairie</em></h2>
        <p>This generative artwork, quite simply, renders a prairie, featuring rolling hills and blooming flowers. <em>Prairie</em> utilizes surface normals to simulate light and shadows. Noise is used to control the flora that grow, and the entire scene is rendered from back to front in 'slices'.</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/prairie/prairie-3.gif" alt="Prairie 3" />
            <img src="data/genart/prairie/prairie-8.png" alt="Prairie 8" />
            <img src="data/genart/prairie/prairie-4.gif" alt="Prairie 4" />
            <img src="data/genart/prairie/prairie-5.png" alt="Prairie 5" />
            <img src="data/genart/prairie/prairie-6.png" alt="Prairie 6" />
            <img src="data/genart/prairie/prairie-7.png" alt="Prairie 7" />
            <img src="data/genart/prairie/prairie-1.png" alt="Prairie 1" />
            <img src="data/genart/prairie/prairie-2.gif" alt="Prairie 2" />
        </div>

        <h2>Experiments in Paintbrush Texture</h2>
        <p>These outputs are from an experiment in creating a realistic paintbrush texture. I was especially interested in recreating the effects caused by individual bristles moving paint. This experiment uses a designed paintbrush class to control the shape of individual bristles as it draws a line segment. The experiment considers the angle of the drawn line with the three-dimensional paint shape that would be created to add bristle texture to each paint stroke. Further, the shape of the brush stroke considers the tapering caused by lifting the brush as the stroke ends.</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/paintbrush/paintbrush-1.gif" alt="Paintbrush 1" />
            <img src="data/genart/paintbrush/paintbrush-4.png" alt="Paintbrush 4" />
            <img src="data/genart/paintbrush/paintbrush-2.gif" alt="Paintbrush 2" />
            <img src="data/genart/paintbrush/paintbrush-5.png" alt="Paintbrush 5" />
            <img src="data/genart/paintbrush/paintbrush-6.png" alt="Paintbrush 6" />
            <img src="data/genart/paintbrush/paintbrush-7.png" alt="Paintbrush 7" />
            <img src="data/genart/paintbrush/paintbrush-3.png" alt="Paintbrush 3" />
        </div>

        <h3><em>Cutouts</em></h3>
        <p>This work recreates layers of cut-out paper, viewing the interesting patterns they make when overlaid. Each layer draws a shadow beneath it to create a sense of depth in each composition. By balancing randomly placed objects with symmetrically placed ones, the outputs feel unique yet controlled.</p>

        <h3>Selected Generations</h3>
        <div class="image-row">
            <img src="data/genart/cutouts/cutouts-1.jpg" alt="Cutouts 1" />
            <img src="data/genart/cutouts/cutouts-2.jpg" alt="Cutouts 2" />
            <img src="data/genart/cutouts/cutouts-3.jpg" alt="Cutouts 3" />
            <img src="data/genart/cutouts/cutouts-4.jpg" alt="Cutouts 4" />
            <img src="data/genart/cutouts/cutouts-5.jpg" alt="Cutouts 5" />
            <img src="data/genart/cutouts/cutouts-6.jpg" alt="Cutouts 6" />
            <img src="data/genart/cutouts/cutouts-7.jpg" alt="Cutouts 7" />
            <img src="data/genart/cutouts/cutouts-8.jpg" alt="Cutouts 8" />
            <img src="data/genart/cutouts/cutouts-9.jpg" alt="Cutouts 9" />
            <img src="data/genart/cutouts/cutouts-10.jpg" alt="Cutouts 10" />
        </div>

        <hr>

        <h1 id="research">Research</h1>
        <p>My research explores human-machine pairing for machine learning methodologies, specifically as it is applied to biometric tasks. My work explores applying human-salient knowledge in the training of image-processing networks. I work with the University of Notre Dame's Computer Vision Research Laboratory and Trusted AI team. I am advised by Prof. Adam Czajka.</p>

        <h2>Grains of Saliency: Optimizing Saliency-based Training of Biometric Attack Detection Models</h2>
        <p>Colton R. Crum, <b>Samuel Webster</b>, Adam Czajka</p>
        <a href="https://arxiv.org/abs/2405.00650">Link to paper on arXiv</a>
        <p>Accepted to and presented at the <a href="https://ijcb2024.ieee-biometrics.org/accepted-papers/#:~:text=Spectral%20Iris%20Recognition-,Grains,-of%20Saliency%3A%20Optimizing">International Joint Conference on Biometrics (IJCB) 2024</a></p>

        <p><b>Contributions:</b></p>
        <ul>
            <li>Individually presenting paper at IJCB conference in 'Spotlight' talk as well as poster session</li>
            <li>Creating conference Spotlight presentation and poster, as well as compiled GitHub repository materials</li>
            <li>Assisted writing and editing paper</li>
            <li>Writing algorithms used to generate the proposed salience granularities as well as generating saliency with them</li>
            <li>Training and reporting performance statistics for iris presentation attack detection (PAD) models</li>
        </ul>

        <details>
            <summary>View Paper</summary>
            <embed src="data/research/grains/grains-paper.pdf" type="application/pdf" width="100%" height="600px" />
        </details>

        <details>
            <summary>View Poster</summary>
            <embed src="data/research/grains/grains-poster.pdf" type="application/pdf" width="100%" height="600px" />
        </details>

        <details>
            <summary>View Spotlight</summary>
            <embed src="data/research/grains/grains-spotlight.pdf" type="application/pdf" width="100%" height="600px" />
        </details>

        <h2>Saliency-guided Training of Fingerprint Presentation Attack Detection Models</h2>
        <p><b>Samuel Webster</b>, Adam Czajka</p>
        <p>This research is currently underway and doesn't yet have a written paper. We are planning for submission in April, 2025 to IJCB 2025.</p>
        
        <p><b>Contributions:</b> All (project lead)</p>
        <p>This work is researching the efficacy of saliency-guided training in fingerprint PAD, being the first research to utilize salient annotations for any fingerprint task. So far, we've identified multiple configurations where saliency-guided training of fingerprint PAD models outperform their non-guided counterparts; however, the returns presented by this technique are limited when compared to their demonstrated success in other biometric domains. We have integrated saliency into training of fingerprint PAD models through both image-level transformations that supress non-salient regions as well as within the loss function by aligning model CAMs to salient regions. We've currently explored multiple forms of 'pseudo-saliency', which is saliency annotations from non-human sources, from various SOTA fingerprint-processing software, such as NBIS contrast maps and Neurotech VeriFinger minutiae identification for minutiae-based saliency. Presently, saliency maps sourced drawing on minutiae points and then inverting the map perform best. Next steps in this work is a dataset collection of human annotators completing the fingerprint PAD test and subsequently using their annotations to train and test fingerprint PAD models.</p>

        <hr>

        <h1 id="projects">Relevant Projects</h1>

        <h2>Audio Sample Generation using a Variational Autoencoder</h2>
        <p>Created as course project for <em>Neural Networks</em></p>
        <p>This project explores the use of a variational autoencoder (VAE) to generate audio samples. The VAE is trained on a dataset of audio samples from Google Magenta's NSynth dataset. The VAE is trained to encode audio samples into a latent space and then decode them back into audio samples. The VAE is then used to generate new audio samples by sampling from the latent space. The audio samples are both ingested and generated using spectrograms, which enables convolutional processing. This data format, however, made it difficult to generate high-fidelity, low-noise samples from the autoencoder.</p>
        <a href="https://github.com/samjwebster/samplegen">GitHub Repository</a>
    </div>    
</body>
</html>